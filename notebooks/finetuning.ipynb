{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN fine tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will load the CNN , freeze the layers we want to leave untouched, and finetune the remaining ones. The image dataset was organized into an appropriate subfolder structure in the notbook called \"image_sorting.ipynb\".\n",
    "In this dataset, each image consists in three channels: one actin, one tubulin, and one DAPI, which correspond to different structures of the cells that get coloured prior to the micriscopy image capturing. Each of these channel is stored as a single image. We therefore need to reconstitute the 3D tensors from the three channels of these images before training the CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's first import the packages we'll need\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import multiprocessing\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Inception V3 model\n",
    "model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "model.eval();\n",
    "\n",
    "torch.set_num_threads(15)  # Set the number of intra-op threads\n",
    "torch.set_num_interop_threads(15)  # Set the number of inter-op threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to freeze all layers except for the last fully connected layer, and finetune this one only. We will then try an alternative approach, by visualizing the features detected by the CNN, freeze layers that detect high level features, and fine tune those which detect rather low level ones. The features visualization is performed in notebook \"CNN_features_visualization\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#replace the last fc layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 12) \n",
    "\n",
    "#set parameters of last fc open for fine tunning\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a class that aims at reconsituting the 3 channels of the picture (Actin, Tubulin and DAPI). In the rest of the code, we will name these channels ATD, including in the variable names, to not cause potential confusion with RGB channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATDImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.image_paths = []\n",
    "        for cls in self.classes:\n",
    "            a_path = os.path.join(root_dir, cls, 'actin')\n",
    "            t_path = os.path.join(root_dir, cls, 'tubulin')\n",
    "            d_path = os.path.join(root_dir, cls, 'dapi')\n",
    "            for img_name in os.listdir(a_path):\n",
    "                self.image_paths.append((os.path.join(a_path, img_name),\n",
    "                                         os.path.join(t_path, img_name),\n",
    "                                         os.path.join(d_path, img_name),\n",
    "                                         cls))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a_path, t_path, d_path, cls = self.image_paths[idx]\n",
    "        a_img = Image.open(a_path).convert('L')\n",
    "        t_img = Image.open(t_path).convert('L')\n",
    "        d_img = Image.open(d_path).convert('L')\n",
    "        img = Image.merge('RGB', (a_img, t_img, d_img))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.classes.index(cls)\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "dataset = ATDImageDataset(root_dir='sorted/train/', transform = transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define  loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#list to store losses\n",
    "losses = []\n",
    "\n",
    "#define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloader:  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the appropriate device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
