# Cell2Structure
![Cell2Structure Logo](images/Cell2Structure_orig_wide_logo.jpg "Cell2Structure Logo")  
<span style="font-size:8px">Image generated by ChatGPT - Image Generator</span>  

*This GitHub Repository is part of a Capstone project (SIADS-699) of the MADS (Master of Applied Data Science) program of the University of Michigan, School of Information.*

## Introduction
High content screening (HCS) consists in an approach of cell-based screening in drug discovery. It consists in treating cells in culture with a large set of chemical compounds, and to acquire microscopy images of these cells post treatment. The modifications of the cells induced by chemical treatment are a signature of the mode of action (MoA) of the chemical compound used. The objective is to discover new potent chemical compounds to obtain a given MoA, or new MoA, potentially leading to new treatments. 

Identification of the MoA can be done using picture recognition algorithms like convolutional neural networks (CNN). The chemical treatment induces modifications in the cells structures that can be recognized by CNN. Embeddings generated by a CNN trained to recognize MoA contain encoded information on the cell structure post treatment.  
The objective of our project is  to address the following high-level question:
* Can cell image embedding vectors be used as a translator between the image space and the space of chemical structures?

This project consists in two main parts:
* Training of a classifier using the Inception v3 architecture in Pytorch, to classify high content cell screening images for the mode of action (MoA) of chemical compounds used to treat the cells
* Exploring of the embeddings resulting from processing cell images with the classifier mentioned above, and the chemical compound structures, to detect potential for mapping from images to chemical structures.

## Python Environment Setup
Besides the standard data science Python libraries such as `Pandas`, `Numpy` and `Scikit-Learn` this project in addition uses the following ones:  
* PyTroch
* torchvision
* RDKit (cheminformatics library)
* InMoose (current pycombat implementation used for batch correction of genomics data)  

The Python environment can be set up using pip or conda/mamba  
_pip_
```
pip install -r requirements.txt
```  
_conda/mamba_  
```
conda env create -f environment.yml
```

## Project Configuration File
The project uses global configuration file  
[project_config.toml](project_config.toml)  
This file contains paths, file names and parameters for most of the scripts.  
In addition to the global configuration a project utilities Python module had been created  
[project_utils.py](src\project_utils.py)
## BBBC021 Dataset
We used the publicly available [BBBC021 dataset](https://bbbc.broadinstitute.org/BBBC021) from the Broad Institute's Broad Bioimage Benchmark Collection [^1]. This dataset is mainly used for developing and comparing image-base profiling experiments. The dataset consists of CSV files contining the image metadata as well as the file names and 55 ZIP files containing the actual images.  
In addition to the original metadata provided along with the images a second version got created containing manually labled MoAs based on DrugBank, ChEML and PubChem:  
[BBBC021_final_enhanced_dataset.csv](data\processed\BBBC021_final_enhanced_dataset.csv)
### Downloading the images
The images are download usin the following Linux shell script:  
[get_bbbc021_images.sh](src/get_bbbc021_images.sh)  
Downloading and unzipping the image files can take up to 30 min or longer, therefore this script is meant to run as SLURM batch job. It uses the setup of UMICH GreatLakes cluster. Running it in another environment need changes to the paths specified in the script.  
### Downloading and preprocessing the metadata
The following Python script downloads the metadata CSV files:  
[get_dataset.py](src/get_dataset.py)  
After downloading the CSV files the preprocessing is done via the Python script:  
[preproc_dataset.py](src/preproc_dataset.py)  
This script takes all 3 CSV files and merges it into one dataset which is used throughout the project.
### Data Exploration
An EDA had been conducted after downloading and preprocessing the CSV files. The analysis can be found in the notebook:  
[Cell2Structure - Data Exploration](notebooks/BBBC021_data_exploration.ipynb)  

# Classifier training attempt 1
We originally intended to perform the classifier training using the jupyter notebook "notebooks/finetuning.ipynb". In this notebook, we retrain onyl the last fully connected layer. For this attempt, we organized the training data into a subfolder structure corresponding to the class label of each image. The notebook "notebooks/image_sorting.ipynb" contains the program to automatically sort the images into the right folder structure.

This apporach led to slow cross entropy loss decrease, and we therefore switched to another approach: we fine tuned the last convolutional layers of the CNN on our dataset in addition to training the last fully connected layer. 

# Classifier training attempt 2
We first identified which convolutional layers made most sense to fine tune, in the notebook "notebooks/CNN_features_visualization.ipynb". We then unfroze the weights of these layers to retrain them. 
We then switched from a jupyter notebook to a .py script to finetune the model using a GPU. The script is available in "src/model_finetuning.py". 

# Embedding generation

# Embedding clustering
Embedding clustering was performed in notebook "notebooks/Embedding_clustering.ipynb"

# Chemical structure of compounds exploration
Exploration of the compounds chemical structure was performed in notebooks "notebooks/Compound_similarity_analysis.ipynb" and "notebooks/Compound_similarity_analysis_descr.ipynb"

[^1]: We used image set [BBBC021v1](https://bbbc.broadinstitute.org/bbbc/BBBC021) [[Caie et al., Molecular Cancer Therapeutics, 2010](http://dx.doi.org/10.1158/1535-7163.MCT-09-1148)], available from the Broad Bioimage Benchmark Collection [[Ljosa et al., Nature Methods, 2012](http://dx.doi.org/10.1038/nmeth.2083)].