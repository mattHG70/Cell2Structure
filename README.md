# Cell2Structure
Capstone project (SIADS-699) as part of the MADS program of the University of Michigan, School of Information

# Introduction
High content screening (HCS) consists in an approach of cell-based screening in drug discovery. It consists in treating cells in culture with a large set of chemical compounds, and to acquire microscopy images of these cells post treatment. The modifications of the cells induced by chemical treatment are a signature of the mode of action (MoA) of the chemical compound used. The objective is to discover new potent chemical compounds to obtain a given MoA, or new MoA, potentially leading to new treatments. 

Identification of the MoA can be done using picture recognition algorithms like convolutional neural networks (CNN). The chemical treatment induces modifications in the cells structures that can be recognized by CNN. Embeddings generated by a CNN trained to recognize MoA contain encoded information on the cell structure post treatment. 
The objective of our project is  to address the following high-level question:
â€¢	Can cell image embedding vectors be used as a translator between the image space and the space of chemical structures?

This project consists in two main parts:
- Training of a classifier using the Inception v3 architecture in Pytorch, to classify high content cell screening images for the mode of action (MoA) of chemical compounds used to treat the cells
- Exploring of the embeddings resulting from processing cell images with the classifier mentioned above, and the chemical compound structures, to detect potential for mapping from images to chemical structures.

# Dataset
The classifier training was performed using the dataset publicly available on the BBBC resource (Broad Institute's Imaging Platform. BBBC021 dataset https://bbbc.broadinstitute.org/BBBC021.) The notebook BBBC021_data_exploration.ipynb contains the data exploration of this dataset.

# Classifier training attempt 1
We originally intended to perform the classifier training using the jupyter notebook "notebooks/finetuning.ipynb". In this notebook, we retrain onyl the last fully connected layer. For this attempt, we organized the training data into a subfolder structure corresponding to the class label of each image. The notebook "notebooks/image_sorting.ipynb" contains the program to automatically sort the images into the right folder structure.

This apporach led to slow cross entropy loss decrease, and we therefore switched to another approach: we fine tuned the last convolutional layers of the CNN on our dataset in addition to training the last fully connected layer. 

# Classifier training attempt 2
We first identified which convolutional layers made most sense to fine tune, in the notebook "notebooks/CNN_features_visualization.ipynb". We then unfroze the weights of these layers to retrain them. 
We then switched from a jupyter notebook to a .py script to finetune the model using a GPU. The script is available in "src/model_finetuning.py". 

# Embedding generation

# Embedding clustering
Embedding clustering was performed in notebook "notebooks/Embedding_clustering.ipynb"

# Chemical structure of compounds exploration
Exploration of the compounds chemical structure was performed in notebooks "notebooks/Compound_similarity_analysis.ipynb" and "notebooks/Compound_similarity_analysis_descr.ipynb"
